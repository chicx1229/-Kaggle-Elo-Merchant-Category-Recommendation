{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7e2ea3-ddf3-41eb-82bf-84355883be41",
   "metadata": {},
   "source": [
    "# <center>3. 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1567646-8853-42dd-b80a-27099ab15b12",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/EfkhZ7FT89dCacb.png\" alt=\"image-20211023143401397\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a83a2-97af-4c2d-8ba3-b93a54a6870f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;transaction数据集则相对复杂，该数据集是有一张商户数据merchants.csv和两张交易数据表处理后合并得到，该过程如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895cc5a-b24e-4f02-862f-3f64e96ef9f3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/vwXiQcd3sWfqhSY.png\" alt=\"image-20211023144942013\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30584f-2cc5-4286-aa77-22a29e1fef0e",
   "metadata": {},
   "source": [
    "接下来，我们就依据这三张表进行后续操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f590691-47d0-46e8-aa52-ec4905f73b2c",
   "metadata": {},
   "source": [
    "## 一、特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59d069-f5c4-45ac-8b76-ae8c5d0b2569",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先需要对得到的数据进一步进行特征工程处理。一般来说，对于已经清洗完的数据，特征工程部分核心需要考虑的问题就是特征创建（衍生）与特征筛选，也就是先尽可能创建/增加可能对模型结果有正面影响的特征，然后再对这些进行挑选，以保证模型运行稳定性及运行效率。此处使用两种特征衍生的方法，即创建通用组合特征与业务统计特征；并在特征创建完毕后，使用另外一种基础而通用的特征筛选的方法：基于皮尔逊相关系数的Filter方法进行特征筛选。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e70af-0c85-43fa-b35c-5554e44d516f",
   "metadata": {},
   "source": [
    "### 1.通用组合特征创建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed921b14-e248-44d8-a45b-0e26f724b748",
   "metadata": {},
   "source": [
    "#### 1.1 通用组合特征的创建方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502390b-75fc-40b0-bf8f-1e49f1941db2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先是尝试创建一些通用组合特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0e84a-c0b9-4a1f-85ad-c3ec242a0dcc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;所谓通用组合特征，指的是通过统计不同离散特征在不同取值水平下、不同连续特征取值之和创建的特征，并根据card_id进行分组求和。具体创建过程我们可以如下简例来进行理解："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a2353-67a4-4581-b780-e062fdc8b39d",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/KUTtb32o9eS1MJW.png\" alt=\"image-20211023153800138\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d287b57-bdea-41e9-a52b-504eb90af9c7",
   "metadata": {},
   "source": [
    "通过该方法创建的数据集，不仅能够尽可能从更多维度表示每个card_id的消费情况，同时也能够顺利和训练集/测试集完成拼接，从而带入模型进行建模。相关过程我们可以借助Python中的字典对象类型来进行实现，上述简例实现过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38803d7-b3da-42df-b959-50f05575cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfaff14-0f9d-4d57-ae93-ed4251335393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  A  B  C  D\n",
       "0        1  1  2  4  7\n",
       "1        2  2  1  5  5\n",
       "2        1  1  2  1  4\n",
       "3        3  2  2  5  8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 借助字典创建DataFrame\n",
    "d1 = {'card_id':[1, 2, 1, 3], \n",
    "      'A':[1, 2, 1, 2], \n",
    "      'B':[2, 1, 2, 2], \n",
    "      'C':[4, 5, 1, 5], \n",
    "      'D':[7, 5, 4, 8],}\n",
    "\n",
    "t1 = pd.DataFrame(d1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c004b7d-c49c-4f27-9288-211689c6604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标注特征类别\n",
    "numeric_cols = ['C', 'D']\n",
    "category_cols = ['A', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d979f4-439d-4415-a8db-7c45bad3d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个以id为key、空字典为value的字典\n",
    "features = {}\n",
    "card_all = t1['card_id'].values.tolist()\n",
    "for card in card_all:\n",
    "    features[card] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b27f8a-ef64-4181-af4e-4de4ef827720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {}, 2: {}, 3: {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c5c967-2963-4a7d-85df-56e657cb2da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card_id', 'A', 'B', 'C', 'D']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有字段名称组成的list\n",
    "columns = t1.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615b0aa0-1440-4da4-993b-374603f8757a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 其中card_id在list当中的索引值\n",
    "idx = columns.index('card_id')\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8c08ef-37bf-4ab7-bb67-96f9dbcb03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 离散型字段的索引值\n",
    "category_cols_index = [columns.index(col) for col in category_cols]\n",
    "category_cols_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503e10ea-c5d2-46ab-aef7-5605ea206d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 连续型字段的索引值\n",
    "numeric_cols_index = [columns.index(col) for col in numeric_cols]\n",
    "numeric_cols_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace64c60-bbfb-49cf-9e14-4db87a777f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对离散型字段的不同取值和连续型字段两两组合\n",
    "# 同时完成分组求和\n",
    "for i in range(t1.shape[0]):\n",
    "    va = t1.loc[i].values\n",
    "    card = va[idx]\n",
    "    for cate_ind in category_cols_index:\n",
    "        for num_ind in numeric_cols_index:\n",
    "            col_name = '&'.join([columns[cate_ind], str(va[cate_ind]), columns[num_ind]])\n",
    "            features[card][col_name] = features[card].get(col_name, 0) + va[num_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd7761-411c-4c99-b92b-006df7c684bb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后查看features最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6565ca79-ebf9-420c-85dc-67639835fe92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'A&1&C': 5, 'A&1&D': 11, 'B&2&C': 5, 'B&2&D': 11},\n",
       " 2: {'A&2&C': 5, 'A&2&D': 5, 'B&1&C': 5, 'B&1&D': 5},\n",
       " 3: {'A&2&C': 5, 'A&2&D': 8, 'B&2&C': 5, 'B&2&D': 8}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1024ae8c-58f1-45ab-8e57-5d29f812fcd1",
   "metadata": {},
   "source": [
    "能够发现，此时features就是一个已经包含了离散变量的不同取值和连续变量两两组合成新特征后在不同card_id下的分组求和结果。接下来我们将其转化为DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f13830a6-2232-41f0-9d0a-f65b05142a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>A&amp;1&amp;C</th>\n",
       "      <th>A&amp;1&amp;D</th>\n",
       "      <th>B&amp;2&amp;C</th>\n",
       "      <th>B&amp;2&amp;D</th>\n",
       "      <th>A&amp;2&amp;C</th>\n",
       "      <th>A&amp;2&amp;D</th>\n",
       "      <th>B&amp;1&amp;C</th>\n",
       "      <th>B&amp;1&amp;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  A&1&C  A&1&D  B&2&C  B&2&D  A&2&C  A&2&D  B&1&C  B&1&D\n",
       "0        1    5.0   11.0    5.0   11.0    NaN    NaN    NaN    NaN\n",
       "1        2    NaN    NaN    NaN    NaN    5.0    5.0    5.0    5.0\n",
       "2        3    NaN    NaN    5.0    8.0    5.0    8.0    NaN    NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转化成df\n",
    "df = pd.DataFrame(features).T.reset_index()\n",
    "\n",
    "# 标注所有列\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "# 修改df的特征名称\n",
    "df.columns = ['card_id'] + cols[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f77e60d-08a2-4bf3-b612-531bc130f360",
   "metadata": {},
   "source": [
    "至此我们就完成了在极简数据集上进行通用组合特征的创建工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939dba78-131d-4573-89db-fe217b8a8102",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，通过上述过程不难发现，这种特征创建的方式能够非常高效的表示更多数据集中的隐藏信息，不过该方法容易产生较多空值，在后续建模过程中需要考虑特征矩阵过于稀疏从而带来的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01194c-3b1e-441d-b8f4-24587a27b608",
   "metadata": {},
   "source": [
    "#### 1.2 基于transaction数据集创建通用组合特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604cce8d-a7e9-4f3b-b23f-2d1fde1de497",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们将上述过程应用于建模真实数据，即在此前已经清洗完的transaction数据集上来完成通用组合特征的创建工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ebafd2-59ff-4cdf-beb1-72a2e7896b7c",
   "metadata": {},
   "source": [
    "- 数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f8ca8-20e9-4f28-8eb3-3cbf8cd214fe",
   "metadata": {},
   "source": [
    "&emsp;&emsp;此处读取的transaction是此前创建的transaction_d_pre.csv数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60f5a08-27f2-46b2-8f24-2e81a0cbea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocess/train_pre.csv')\n",
    "test =  pd.read_csv('preprocess/test_pre.csv')\n",
    "transaction = pd.read_csv('preprocess/transaction_d_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4759ce-ca98-42f7-8f29-392b96717b91",
   "metadata": {},
   "source": [
    "- 字段类型标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548fd17c-fb67-4d50-a1b6-54042bd0539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标注离散字段or连续型字段\n",
    "numeric_cols = ['purchase_amount', 'installments']\n",
    "\n",
    "category_cols = ['authorized_flag', 'city_id', 'category_1',\n",
    "       'category_3', 'merchant_category_id','month_lag','most_recent_sales_range',\n",
    "                 'most_recent_purchases_range', 'category_4',\n",
    "                 'purchase_month', 'purchase_hour_section', 'purchase_day']\n",
    "\n",
    "id_cols = ['card_id', 'merchant_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf92a02-804c-4f51-9a1f-a5b60616e5cd",
   "metadata": {},
   "source": [
    "- 特征创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3080b314-5ab5-422e-86cf-dad5e6d4a4ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.78152775764465 s\n",
      "156.30035185813904 s\n",
      "233.77025890350342 s\n",
      "310.8533182144165 s\n",
      "388.58491253852844 s\n",
      "465.7131087779999 s\n",
      "542.9651112556458 s\n",
      "620.2659630775452 s\n",
      "697.4840726852417 s\n",
      "775.1001462936401 s\n",
      "854.336339712143 s\n",
      "931.5795841217041 s\n",
      "1009.2299842834473 s\n",
      "1086.400577545166 s\n",
      "1163.4447948932648 s\n",
      "1240.6105089187622 s\n",
      "1317.9271388053894 s\n",
      "1395.526971578598 s\n",
      "1472.8169467449188 s\n",
      "1550.1737365722656 s\n",
      "1628.1112337112427 s\n",
      "1705.3568155765533 s\n",
      "1782.6971368789673 s\n",
      "1860.14785695076 s\n",
      "1937.7663321495056 s\n",
      "2015.3726768493652 s\n",
      "2093.225520133972 s\n",
      "2171.1658523082733 s\n",
      "2249.178324699402 s\n",
      "2327.6118054389954 s\n",
      "2406.600684404373 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建字典用于保存数据\n",
    "features = {}\n",
    "card_all = train['card_id']._append(test['card_id']).values.tolist()\n",
    "for card in card_all:\n",
    "    features[card] = {}\n",
    "     \n",
    "# 标记不同类型字段的索引\n",
    "columns = transaction.columns.tolist()\n",
    "idx = columns.index('card_id')\n",
    "category_cols_index = [columns.index(col) for col in category_cols]\n",
    "numeric_cols_index = [columns.index(col) for col in numeric_cols]\n",
    "\n",
    "# 记录运行时间\n",
    "s = time.time()\n",
    "num = 0\n",
    "\n",
    "# 执行循环，并在此过程中记录时间\n",
    "for i in range(transaction.shape[0]):\n",
    "    va = transaction.loc[i].values\n",
    "    card = va[idx]\n",
    "    for cate_ind in category_cols_index:\n",
    "        for num_ind in numeric_cols_index:\n",
    "            col_name = '&'.join([columns[cate_ind], str(va[cate_ind]), columns[num_ind]])\n",
    "            features[card][col_name] = features[card].get(col_name, 0) + va[num_ind]\n",
    "    num += 1\n",
    "    if num%1000000==0:\n",
    "        print(time.time()-s, \"s\")\n",
    "del transaction\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d19e9b-5778-462e-b74e-afc11730ba76",
   "metadata": {},
   "source": [
    "&emsp;&emsp;能够发现，整体运行所需时间较长。此外，此处需要注意的是，card_id的提取并不是从transaction从提取，而是从训练集和测试集中提取，大家想想看是什么原因？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720c14b-f469-4b52-bb07-62a3a143ed50",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在提取完特征后，接下来即可将带有交易数据特征的合并入训练集和测试集了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f35fcb9-756d-43ff-9233-d05398c53f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字典转dataframe\n",
    "df = pd.DataFrame(features).T.reset_index()\n",
    "del features\n",
    "cols = df.columns.tolist()\n",
    "df.columns = ['card_id'] + cols[1:]\n",
    "\n",
    "# 生成训练集与测试集\n",
    "train = pd.merge(train, df, how='left', on='card_id')\n",
    "test =  pd.merge(test, df, how='left', on='card_id')\n",
    "del df\n",
    "train.to_csv(\"preprocess/train_dict.csv\", index=False)\n",
    "test.to_csv(\"preprocess/test_dict.csv\", index=False)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443daeeb-cc57-4118-9e6d-6765124b6841",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们就完成了从transaction中提取通用特征的过程。简单查看数据集基本情况："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915a415-4602-4fca-a67e-e50a699d9b2a",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/ZY75eSk3pAayoJn.png\" alt=\"image-20211023161451438\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6a231-9449-407f-81ee-5b04d2fac602",
   "metadata": {},
   "source": [
    "### 2.业务统计特征创建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea680b36-7cd2-4830-94c4-e6fe8e92f263",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然，除了通用组合特征外，我们还可以考虑从另一个角度进行特征提取，那就是先根据card_id来进行分组，然后统计不同字段再各组内的相关统计量，再将其作为特征，带入进行建模。其基本构造特征思路如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c3e22-7aa0-4b0f-b46d-35199b970cdf",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/NupDc9JnBbHRPgU.png\" alt=\"image-20211023162730619\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f4af6-3da4-40fb-b818-e58ce2192fe6",
   "metadata": {},
   "source": [
    "该过程并不复杂，可以通过pandas中的groupby过程迅速实现。和此前特征构造的思路不同，通过该方法构造的特征，不会存在大量的缺失值，并且新增的列也将相对较少。代码实现过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505de5e0-9d77-4d4d-9c89-f53caece8d2b",
   "metadata": {},
   "source": [
    "- 数据读取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a353954d-c4ba-4136-bfa7-f12186e76769",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = pd.read_csv('preprocess/transaction_g_pre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04bd2b-726c-446a-8e56-6afc4980cb56",
   "metadata": {},
   "source": [
    "- 字段类型标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef47e7ce-beaa-4598-9a0c-e258c4097e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标注离散字段or连续型字段\n",
    "numeric_cols = ['authorized_flag',  'category_1', 'installments',\n",
    "       'category_3',  'month_lag','purchase_month','purchase_day','purchase_day_diff', 'purchase_month_diff',\n",
    "       'purchase_amount', 'category_2', \n",
    "       'purchase_month', 'purchase_hour_section', 'purchase_day',\n",
    "       'most_recent_sales_range', 'most_recent_purchases_range', 'category_4']\n",
    "categorical_cols = ['city_id', 'merchant_category_id', 'merchant_id', 'state_id', 'subsector_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cca76d-ad08-4668-bbc5-f9be3b560a9a",
   "metadata": {},
   "source": [
    "- 特征提取过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ace5ff6b-ab39-4447-9e70-bcadda5f9857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建空字典\n",
    "aggs = {}\n",
    "\n",
    "# 连续/离散字段统计量提取范围\n",
    "for col in numeric_cols:\n",
    "    aggs[col] = ['nunique', 'mean', 'min', 'max','var','skew', 'sum']\n",
    "for col in categorical_cols:\n",
    "    aggs[col] = ['nunique']    \n",
    "aggs['card_id'] = ['size', 'count']\n",
    "cols = ['card_id']\n",
    "\n",
    "# 借助groupby实现统计量计算\n",
    "for key in aggs.keys():\n",
    "# 将每个字段和对应的统计量拼接成新的特征列名，存储在 cols 中。\n",
    "    cols.extend([key+'_'+stat for stat in aggs[key]])\n",
    "\n",
    "df = transaction[transaction['month_lag']<0].groupby('card_id').agg(aggs).reset_index()\n",
    "df.columns = cols[:1] + [co+'_hist' for co in cols[1:]]\n",
    "\n",
    "df2 = transaction[transaction['month_lag']>=0].groupby('card_id').agg(aggs).reset_index()\n",
    "df2.columns = cols[:1] + [co+'_new' for co in cols[1:]]\n",
    "df = pd.merge(df, df2, how='left',on='card_id')\n",
    "\n",
    "df2 = transaction.groupby('card_id').agg(aggs).reset_index()\n",
    "df2.columns = cols\n",
    "df = pd.merge(df, df2, how='left',on='card_id')\n",
    "del transaction\n",
    "gc.collect()\n",
    "\n",
    "# 生成训练集与测试集\n",
    "train = pd.merge(train, df, how='left', on='card_id')\n",
    "test =  pd.merge(test, df, how='left', on='card_id')\n",
    "del df\n",
    "train.to_csv(\"preprocess/train_groupby.csv\", index=False)\n",
    "test.to_csv(\"preprocess/test_groupby.csv\", index=False)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da996a7d-73aa-4a90-891a-c3321ae11897",
   "metadata": {},
   "source": [
    "执行完毕后，我们也可以简单查看数据集基本情况："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5d09c-55a7-4be7-9928-334b0d1c0630",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.loli.net/2021/10/23/HpI1QuM6ZvtkS7f.png\" alt=\"image-20211023162707542\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed493b4c-5817-4c0e-9ba9-eeb5158f412d",
   "metadata": {},
   "source": [
    "### 3.数据合并"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb72f2ab-bc5e-4112-8fb2-c81d5aa215ef",
   "metadata": {},
   "source": [
    "&emsp;&emsp;至此，我们即完成了从两个不同角度提取特征的相关工作。不过截至目前上述两套方案的特征仍然保存在不同数据文件中，我们需要对其进行合并，才能进一步带入进行建模，合并过程较为简单，只需要将train_dict(test_dict)与train_group(test_group)根据card_id进行横向拼接、然后剔除重复列即可，实现过程如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae9c67-fdc4-4a39-9efb-1ae150c9245b",
   "metadata": {},
   "source": [
    "- 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c4e7219-4175-49b5-9068-af17e59a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = pd.read_csv(\"preprocess/train_dict.csv\")\n",
    "test_dict = pd.read_csv(\"preprocess/test_dict.csv\")\n",
    "train_groupby = pd.read_csv(\"preprocess/train_groupby.csv\")\n",
    "test_groupby = pd.read_csv(\"preprocess/test_groupby.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb5384-0a0e-4898-8cec-f3fb907d1422",
   "metadata": {},
   "source": [
    "- 剔除重复列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32862990-9fb9-4d9f-8b8c-472966eacfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for co in train_dict.columns:\n",
    "    if co in train_groupby.columns and co!='card_id':\n",
    "        del train_groupby[co]\n",
    "for co in test_dict.columns:\n",
    "    if co in test_groupby.columns and co!='card_id':\n",
    "        del test_groupby[co]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d044090-71ba-4d5a-8416-031df430a6f0",
   "metadata": {},
   "source": [
    "- 拼接特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cd4ac85-4c6c-47e6-9050-3bc43f3f067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_dict, train_groupby, how='left', on='card_id').fillna(0)\n",
    "test = pd.merge(test_dict, test_groupby, how='left', on='card_id').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bf3c8-fd9a-4b8c-90cd-db0276cf4fec",
   "metadata": {},
   "source": [
    "> 注，上述操作对缺失值进行了0的填补，此处缺失值并非真正的缺失值，该缺失值只是在特征创建过程没有统计结果的值，这些值从逻辑上来讲其实也都是0。因此此处缺失值填补相当于是数据补全。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa427b96-7d6f-41f4-92fe-c9980212d141",
   "metadata": {},
   "source": [
    "- 数据保存与内存管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa6d1cde-56a9-4302-9df7-e32ea3f259ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.to_csv(\"preprocess/train.csv\", index=False)\n",
    "test.to_csv(\"preprocess/test.csv\", index=False)\n",
    "\n",
    "del train_dict, test_dict, train_groupby, test_groupby\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
