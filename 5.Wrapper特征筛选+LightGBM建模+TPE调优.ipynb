{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c10658-bc84-4e0e-b12f-1a4a21fb57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a2ac2f-fb5d-4465-9641-ba7e7d0bfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocess/train.csv')\n",
    "test = pd.read_csv('preprocess/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea161cb6-77cf-49f1-beb5-62ecffdc3156",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576269ff-834e-4fb4-85a4-7092416b081d",
   "metadata": {},
   "source": [
    "\n",
    "## <center>**Wrapper特征筛选+LightGBM建模+TPE调优**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9f174-b2e9-4674-8194-a3c2ddacaca3",
   "metadata": {},
   "source": [
    "### 1.Wrapper特征筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f3e90-d033-4f73-b27f-997a7317974c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来是特征筛选过程，此处先择使用Wrapper方法进行特征筛选，通过带入全部数据训练一个LightGBM模型，然后通过观察特征重要性，选取最重要的300个特征。当然，为了进一步确保挑选过程的有效性，此处我们考虑使用交叉验证的方法来进行多轮验证。实际多轮验证特征重要性的过程也较为清晰，我们只需要记录每一轮特征重要性，并在最后进行简单汇总即可。我们可以通过定义如下函数完成该过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df280c5e-78dd-4bb4-8b05-8f19749fbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_wrapper(train, test):\n",
    "    \"\"\"\n",
    "    lgm特征重要性筛选函数\n",
    "    :param train:训练数据集\n",
    "    :param test:测试数据集\n",
    "    :return:特征筛选后的训练集和测试集\n",
    "    \"\"\"\n",
    "    \n",
    "    # Part 1.划分特征名称，删除ID列和标签列\n",
    "    print('feature_select_wrapper...')\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "\n",
    "    # Step 2.配置lgb参数\n",
    "    # 模型参数\n",
    "    params_initial = {\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'boosting': 'gbdt',\n",
    "        'min_child_samples': 20,\n",
    "        'bagging_seed': 2020,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 1,\n",
    "        'feature_fraction': 0.7,\n",
    "        'max_depth': -1,\n",
    "        'metric': 'rmse',\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 1,\n",
    "        'objective': 'regression'\n",
    "    }\n",
    "    # 控制参数\n",
    "    # 提前验证迭代效果或停止\n",
    "    ESR = 30\n",
    "    # 迭代次数\n",
    "    NBR = 10000\n",
    "    # 打印间隔\n",
    "    VBE = 50\n",
    "    \n",
    "    # Part 3.交叉验证过程\n",
    "    # 实例化评估器\n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    # 创建空容器\n",
    "    fse = pd.Series(0, index=features)\n",
    "    \n",
    "    for train_part_index, eval_index in kf.split(train[features], train[label]):\n",
    "        # 封装训练数据集\n",
    "        train_part = lgb.Dataset(train[features].loc[train_part_index],\n",
    "                                 train[label].loc[train_part_index])\n",
    "        # 封装验证数据集\n",
    "        eval = lgb.Dataset(train[features].loc[eval_index],\n",
    "                           train[label].loc[eval_index])\n",
    "        # 在训练集上进行训练，并同时进行验证\n",
    "        bst = lgb.train(params_initial, train_part, num_boost_round=NBR,\n",
    "                        valid_sets=[train_part, eval],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        early_stopping_rounds=ESR, verbose_eval=VBE)\n",
    "        # 输出特征重要性计算结果，并进行累加\n",
    "        fse += pd.Series(bst.feature_importance(), features)\n",
    "    \n",
    "    # Part 4.选择最重要的300个特征\n",
    "    feature_select = ['card_id'] + fse.sort_values(ascending=False).index.tolist()[:300]\n",
    "    print('done')\n",
    "    return train[feature_select + ['target']], test[feature_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728c1ac6-9c71-45b8-9894-7e45952aeaae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_wrapper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.676599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227016\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1626\n",
      "[LightGBM] [Info] Start training from score -0.390986\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.43695\tvalid's rmse: 3.70629\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttrain's rmse: 3.39251\tvalid's rmse: 3.70281\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.583384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227122\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1629\n",
      "[LightGBM] [Info] Start training from score -0.396781\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.45546\tvalid's rmse: 3.67176\n",
      "[100]\ttrain's rmse: 3.33017\tvalid's rmse: 3.67221\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttrain's rmse: 3.37387\tvalid's rmse: 3.66794\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227089\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1631\n",
      "[LightGBM] [Info] Start training from score -0.390348\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.43208\tvalid's rmse: 3.72216\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttrain's rmse: 3.38524\tvalid's rmse: 3.71798\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.687552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1624\n",
      "[LightGBM] [Info] Start training from score -0.391392\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.42022\tvalid's rmse: 3.7901\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttrain's rmse: 3.39133\tvalid's rmse: 3.78884\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1625\n",
      "[LightGBM] [Info] Start training from score -0.398675\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.46321\tvalid's rmse: 3.60039\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttrain's rmse: 3.43002\tvalid's rmse: 3.59887\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_LGBM, test_LGBM = feature_select_wrapper(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b64ead-cbfd-4523-b734-a39670d8ccbe",
   "metadata": {},
   "source": [
    "查看最终输出结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e937669-3971-44b5-ab12-c8ec9a02ee6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 302)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_LGBM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2eadd4-702c-409e-bfee-b563b42ce845",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们即可带入经过筛选的特征进行建模。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc9e12-18d6-4eaf-9e08-22a1e3745cb0",
   "metadata": {},
   "source": [
    "### 2.LightGBM模型训练与TPE参数优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33bc58-7767-4561-9fa4-4a338cef632c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来，我们进行LightGBM的模型训练过程，和此前的随机森林建模过程类似，我们需要在训练模型的过程同时进行超参数的搜索调优。为了能够更好的借助hyperopt进行超参数搜索，此处我们考虑使用LightGBM的原生算法库进行建模，并将整个算法建模流程封装在若干个函数  内执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea898113-91ec-4d1f-8cc6-1714b4fd006d",
   "metadata": {},
   "source": [
    "- 参数回调函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597a8fa-35fd-42b5-bc94-dc4130f1a915",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先对于lgb模型来说，并不是所有的超参数都需要进行搜索，为了防止多次实例化模型过程中部分超参数被设置成默认参数，此处我们首先需要创建一个参数回调函数，用于在后续多次实例化模型过程中反复申明这部分参数的固定取值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf8503b-3f9c-440d-a30a-90a956b3fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_append(params):\n",
    "    \"\"\"\n",
    "    动态回调参数函数，params视作字典\n",
    "    :param params:lgb参数字典\n",
    "    :return params:修正后的lgb参数字典\n",
    "    \"\"\"\n",
    "    params['feature_pre_filter'] = False\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'rmse'\n",
    "    params['bagging_seed'] = 2020\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38198834-3eb4-4561-b3c6-464b541dd6b0",
   "metadata": {},
   "source": [
    "- 模型训练与参数优化函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6524a82-2e19-4a80-8a3a-4f7225896ca3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;接下来就是更加复杂的模型训练与超参数调优的的过程。不同于sklearn内部的调参过程，此处由于涉及多个不同的库相互协同，外加本身lgb模型参数就较为复杂，因此整体模型训练与优化过程较为复杂，我们可以通过下述函数来执行该过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "102ef0a9-ce3e-4c75-a6e2-dfa02b3cc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt(train):\n",
    "    \"\"\"\n",
    "    模型参数搜索与优化函数\n",
    "    :param train:训练数据集\n",
    "    :return params_best:lgb最优参数\n",
    "    \"\"\"\n",
    "    # Part 1.划分特征名称，删除ID列和标签列\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "    \n",
    "    # Part 2.封装训练数据\n",
    "    train_data = lgb.Dataset(train[features], train[label])\n",
    "    \n",
    "    # Part 3.内部函数，输入模型超参数损失值输出函数\n",
    "    def hyperopt_objective(params):\n",
    "        \"\"\"\n",
    "        输入超参数，输出对应损失值\n",
    "        :param params:\n",
    "        :return:最小rmse\n",
    "        \"\"\"\n",
    "        # 创建参数集\n",
    "        params = params_append(params)\n",
    "        print(params)\n",
    "        \n",
    "        # 借助lgb的cv过程，输出某一组超参数下损失值的最小值\n",
    "        res = lgb.cv(params, train_data, 1000,\n",
    "                     nfold=2,\n",
    "                     stratified=False,\n",
    "                     shuffle=True,\n",
    "                     metrics='rmse',\n",
    "                     early_stopping_rounds=20,\n",
    "                     verbose_eval=False,\n",
    "                     show_stdv=False,\n",
    "                     seed=2020)\n",
    "        return min(res['rmse-mean']) # res是个字典\n",
    "\n",
    "    # Part 4.lgb超参数空间\n",
    "    params_space = {\n",
    "        'learning_rate': hp.uniform('learning_rate', 1e-2, 5e-1),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n",
    "        'num_leaves': hp.choice('num_leaves', list(range(10, 300, 10))),\n",
    "        'reg_alpha': hp.randint('reg_alpha', 0, 10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
    "        'bagging_freq': hp.randint('bagging_freq', 1, 10),\n",
    "        'min_child_samples': hp.choice('min_child_samples', list(range(1, 30, 5)))\n",
    "    }\n",
    "    \n",
    "    # Part 5.TPE超参数搜索\n",
    "    params_best = fmin(\n",
    "        hyperopt_objective,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=30,\n",
    "        rstate=RandomState(2020))\n",
    "    \n",
    "    # 返回最佳参数\n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918eb7a9-00c7-46c7-9fca-90caf656b42b",
   "metadata": {},
   "source": [
    "接下来我们带入训练数据，测试函数性能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c860c2d6-9e32-4a4e-939b-a1eca83cab6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.7253952770621912, 'bagging_freq': 5, 'feature_fraction': 0.6972128940985931, 'learning_rate': 0.43437628238508774, 'min_child_samples': 6, 'num_leaves': 60, 'reg_alpha': 0, 'reg_lambda': 1.6139256132729207, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931 \n",
      "[LightGBM] [Info] Start training from score -0.390344 \n",
      "  0%|          | 0/30 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.557619162794617, 'bagging_freq': 6, 'feature_fraction': 0.768520768296847, 'learning_rate': 0.4484899481964635, 'min_child_samples': 1, 'num_leaves': 250, 'reg_alpha': 1, 'reg_lambda': 1.9478998979854978, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                          \n",
      "[LightGBM] [Info] Start training from score -0.390344                          \n",
      "{'bagging_fraction': 0.6089577218903197, 'bagging_freq': 8, 'feature_fraction': 0.9078041789694723, 'learning_rate': 0.4000654698261548, 'min_child_samples': 26, 'num_leaves': 60, 'reg_alpha': 4, 'reg_lambda': 9.739071431781486, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                          \n",
      "[LightGBM] [Info] Start training from score -0.390344                          \n",
      "{'bagging_fraction': 0.5823692068559665, 'bagging_freq': 1, 'feature_fraction': 0.9863236467851518, 'learning_rate': 0.44826974213381765, 'min_child_samples': 6, 'num_leaves': 190, 'reg_alpha': 8, 'reg_lambda': 6.424961074528348, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.598225211619325, 'bagging_freq': 4, 'feature_fraction': 0.5548282810909009, 'learning_rate': 0.33699901703548696, 'min_child_samples': 6, 'num_leaves': 100, 'reg_alpha': 5, 'reg_lambda': 8.56187185369514, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9653168636499914, 'bagging_freq': 2, 'feature_fraction': 0.7958338878675355, 'learning_rate': 0.49191469387124415, 'min_child_samples': 6, 'num_leaves': 120, 'reg_alpha': 0, 'reg_lambda': 6.281210819853246, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9746881685291604, 'bagging_freq': 5, 'feature_fraction': 0.6646803214513162, 'learning_rate': 0.07529481190470996, 'min_child_samples': 1, 'num_leaves': 270, 'reg_alpha': 8, 'reg_lambda': 5.37208795616958, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9594369823462314, 'bagging_freq': 1, 'feature_fraction': 0.5205458529613629, 'learning_rate': 0.10394361538901523, 'min_child_samples': 11, 'num_leaves': 180, 'reg_alpha': 9, 'reg_lambda': 8.54732560156507, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.5239402528699113, 'bagging_freq': 4, 'feature_fraction': 0.7242087970134551, 'learning_rate': 0.1388688694778799, 'min_child_samples': 16, 'num_leaves': 120, 'reg_alpha': 0, 'reg_lambda': 7.4552808665141175, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.7002922718759523, 'bagging_freq': 1, 'feature_fraction': 0.6995945996396362, 'learning_rate': 0.13683006962337202, 'min_child_samples': 1, 'num_leaves': 170, 'reg_alpha': 8, 'reg_lambda': 9.573241379549104, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9740731891987577, 'bagging_freq': 9, 'feature_fraction': 0.8294212073704622, 'learning_rate': 0.4788786165054211, 'min_child_samples': 21, 'num_leaves': 180, 'reg_alpha': 3, 'reg_lambda': 9.025378633668943, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.189511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.6595660453511591, 'bagging_freq': 3, 'feature_fraction': 0.7067334738059636, 'learning_rate': 0.03476014344160344, 'min_child_samples': 6, 'num_leaves': 280, 'reg_alpha': 7, 'reg_lambda': 1.5530335205049572, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.6633836872563099, 'bagging_freq': 6, 'feature_fraction': 0.5393971364268482, 'learning_rate': 0.4475746464086467, 'min_child_samples': 21, 'num_leaves': 240, 'reg_alpha': 5, 'reg_lambda': 9.96781356536865, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.8489543397224686, 'bagging_freq': 7, 'feature_fraction': 0.7582778265282211, 'learning_rate': 0.2222331623940236, 'min_child_samples': 21, 'num_leaves': 120, 'reg_alpha': 7, 'reg_lambda': 9.191685626283043, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.8489434703946281, 'bagging_freq': 5, 'feature_fraction': 0.8206802208124425, 'learning_rate': 0.04617153690285374, 'min_child_samples': 26, 'num_leaves': 270, 'reg_alpha': 0, 'reg_lambda': 6.1154939604145255, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.5722064005547208, 'bagging_freq': 9, 'feature_fraction': 0.6351076955262891, 'learning_rate': 0.24123365491719742, 'min_child_samples': 16, 'num_leaves': 220, 'reg_alpha': 4, 'reg_lambda': 5.435241604857383, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.876943709541165, 'bagging_freq': 1, 'feature_fraction': 0.7520250111432751, 'learning_rate': 0.27978139134976193, 'min_child_samples': 16, 'num_leaves': 250, 'reg_alpha': 0, 'reg_lambda': 9.889444738399005, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.180522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7292457974834843, 'bagging_freq': 1, 'feature_fraction': 0.5605178583746184, 'learning_rate': 0.0750382696349759, 'min_child_samples': 26, 'num_leaves': 30, 'reg_alpha': 3, 'reg_lambda': 8.434389500726724, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.211947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7623620409611478, 'bagging_freq': 5, 'feature_fraction': 0.9037817698710914, 'learning_rate': 0.11935511419050072, 'min_child_samples': 21, 'num_leaves': 50, 'reg_alpha': 6, 'reg_lambda': 9.525599018301525, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.6959365208552413, 'bagging_freq': 4, 'feature_fraction': 0.8682613864600894, 'learning_rate': 0.3540190069136353, 'min_child_samples': 11, 'num_leaves': 70, 'reg_alpha': 8, 'reg_lambda': 1.8364446123307276, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7790707500769768, 'bagging_freq': 5, 'feature_fraction': 0.9823224422761904, 'learning_rate': 0.18097980740543457, 'min_child_samples': 26, 'num_leaves': 50, 'reg_alpha': 6, 'reg_lambda': 3.70583513118315, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7657229397838268, 'bagging_freq': 3, 'feature_fraction': 0.6048086694416244, 'learning_rate': 0.18083227043013056, 'min_child_samples': 21, 'num_leaves': 30, 'reg_alpha': 3, 'reg_lambda': 7.765420130465819, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7941491322120129, 'bagging_freq': 2, 'feature_fraction': 0.9314060907023993, 'learning_rate': 0.02215568922918173, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 3.921799580171095, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.8156411479061829, 'bagging_freq': 2, 'feature_fraction': 0.9453575093796732, 'learning_rate': 0.015016007831064087, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 3.6758012630853103, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.190266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9022336069269954, 'bagging_freq': 2, 'feature_fraction': 0.9373662317255621, 'learning_rate': 0.014947332175194025, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 3.5907566887206896, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9092910898548142, 'bagging_freq': 2, 'feature_fraction': 0.9587253380203777, 'learning_rate': 0.01594569445481636, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 0.5437059106621431, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9243731638563496, 'bagging_freq': 2, 'feature_fraction': 0.8579304338996762, 'learning_rate': 0.07045436429758375, 'min_child_samples': 26, 'num_leaves': 10, 'reg_alpha': 2, 'reg_lambda': 3.6181498300907533, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.8208518394986082, 'bagging_freq': 2, 'feature_fraction': 0.9942064788262652, 'learning_rate': 0.17680977265314285, 'min_child_samples': 26, 'num_leaves': 230, 'reg_alpha': 2, 'reg_lambda': 0.014934884031477136, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9087334379512036, 'bagging_freq': 8, 'feature_fraction': 0.9435725455149249, 'learning_rate': 0.28640982898261946, 'min_child_samples': 26, 'num_leaves': 130, 'reg_alpha': 2, 'reg_lambda': 2.818017545083271, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.8733261239697325, 'bagging_freq': 2, 'feature_fraction': 0.8775960565074609, 'learning_rate': 0.011582875040907454, 'min_child_samples': 11, 'num_leaves': 210, 'reg_alpha': 9, 'reg_lambda': 4.553491961304738, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "100%|██████████| 30/30 [02:51<00:00,  5.71s/trial, best loss: 3.6844192003528775]\n"
     ]
    }
   ],
   "source": [
    "best_clf = param_hyperopt(train_LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825b4e5-02e6-46b2-978b-b979b57f9c58",
   "metadata": {},
   "source": [
    "此时best_clf即为lgb模型的最优参数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db06186c-6815-4fe9-8920-ceb79ebebe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9022336069269954,\n",
       " 'bagging_freq': 2,\n",
       " 'feature_fraction': 0.9373662317255621,\n",
       " 'learning_rate': 0.014947332175194025,\n",
       " 'min_child_samples': 5,\n",
       " 'num_leaves': 7,\n",
       " 'reg_alpha': 2,\n",
       " 'reg_lambda': 3.5907566887206896}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3fb4ad-5ac7-4230-8224-80cdd1a63a77",
   "metadata": {},
   "source": [
    "### 3.LightGBM模型预测与结果排名"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa124f63-2cbf-46f6-9d67-3170c8ccaa58",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在搜索出最优参数后，接下来即可进行模型预测了。和此前一样，在实际执行预测时有两种思路，其一是单模型预测，即直接针对测试集进行预测并提交结果，其二则是通过交叉验证提交平均得分，并且在此过程中能同时保留下后续用于stacking集成时所需要用到的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce9b46-a538-4716-a3b9-dd0cc86624eb",
   "metadata": {},
   "source": [
    "- 单模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69f435-057c-40c1-b7af-e89c274c13e0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;首先测试单独模型在测试集上的预测效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "326f09dd-7323-4766-9311-2b2356bf7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次申明固定参数\n",
    "best_clf = params_append(best_clf)\n",
    "\n",
    "# 数据准备过程\n",
    "label = 'target'\n",
    "features = train_LGBM.columns.tolist()\n",
    "features.remove('card_id')\n",
    "features.remove('target')\n",
    "\n",
    "# 数据封装\n",
    "lgb_train = lgb.Dataset(train_LGBM[features], train_LGBM[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3139fe5a-3b82-4ff2-b131-0dcc2d73d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.426494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.393636\n"
     ]
    }
   ],
   "source": [
    "# 在全部数据集上训练模型\n",
    "bst = lgb.train(best_clf, lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6fe1824-10e0-4b1c-a24f-9bf6a877b5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24511938, -2.01595283,  0.1053809 , ..., -0.18190679,\n",
       "       -1.11870804, -0.24511938])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在测试集上完成预测\n",
    "bst.predict(train_LGBM[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d8c3f25-eb32-4a0d-b870-570085e0279a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7213768397255365"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 简单查看训练集RMSE\n",
    "np.sqrt(mean_squared_error(train_LGBM[label], bst.predict(train_LGBM[features])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a351566-bf6f-4bfe-bb08-2b1b3f722ac9",
   "metadata": {},
   "source": [
    "接下来，对测试集进行预测，并将结果写入本地文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93884a9c-386e-43d9-b212-688a014202db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-a18f256f8f74>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_LGBM['target'] = bst.predict(test_LGBM[features])\n"
     ]
    }
   ],
   "source": [
    "test_LGBM['target'] = bst.predict(test_LGBM[features])\n",
    "test_LGBM[['card_id', 'target']].to_csv(\"result/submission_LGBM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30950193-4511-4003-88e4-9a4e0aeaa2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.418856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>-0.752626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.030933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>-0.245119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>-0.366990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.418856\n",
       "1  C_ID_130fd0cbdd -0.752626\n",
       "2  C_ID_b709037bc5 -0.030933\n",
       "3  C_ID_d27d835a9f -0.245119\n",
       "4  C_ID_2b5e3df5c2 -0.366990"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LGBM[['card_id', 'target']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6532f39-3c0c-479e-8d97-cb6b19ae9f40",
   "metadata": {},
   "source": [
    "提交该结果，得到公榜、私榜结果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2178c6-cb0c-4280-96ed-5dfea768861c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2021/12/09/GowrHnvJWMOpxB4.png\" alt=\"image-20211209172112868\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad4e65-0f6b-4302-a0aa-e72bad389c4f",
   "metadata": {},
   "source": [
    "对比此前的随机森林提交的两组结果，汇总情况如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7ff30-dd49-4d2b-91e6-9f33a55d1a2d",
   "metadata": {},
   "source": [
    "| 模型 | Private Score | Public Score |\n",
    "| ------ | ------ | ------ |\n",
    "| randomforest | 3.65455 | 3.74969 |\n",
    "| randomforest+validation | 3.65173 | 3.74954 |\n",
    "| LightGBM | 3.69723 | 3.80436 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b092449-d7ac-446a-a69e-c5048ac3dd02",
   "metadata": {},
   "source": [
    "能够发现，在单模型预测情况下，lgb要略弱于rf，接下来考虑进行交叉验证，以提高lgb模型预测效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e369804-2018-47bf-862b-786a4166a8a3",
   "metadata": {},
   "source": [
    "- 结合交叉验证进行模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fb7c6-ca15-4595-b803-8be7e0ffa90d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;和随机森林借助交叉验证进行模型预测的过程类似，lgb也需要遵照如下流程进行训练和预测，并同时创建后续集成所需数据集以及预测结果的平均值（作为最终预测结果）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cd447-b38e-4bb8-b057-9caa8b2a5a20",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2021/12/08/ALF3cfuSwmB7b8z.png\" alt=\"image-20211208192640281\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336cca17-ff2e-41a5-b60d-632eb798bdd0",
   "metadata": {},
   "source": [
    "执行过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a099a86f-f013-4d39-bd37-e4802e1e6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(train, test, params):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Part 1.选择特征\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "    \n",
    "    # Part 2.再次申明固定参数与控制迭代参数\n",
    "    params = params_append(params)\n",
    "    ESR = 30\n",
    "    NBR = 10000\n",
    "    VBE = 50\n",
    "    \n",
    "    # Part 3.创建结果存储容器\n",
    "    # 测试集预测结果存储器，后保存至本地文件\n",
    "    prediction_test = 0\n",
    "    # 验证集的模型表现，作为展示用\n",
    "    cv_score = []\n",
    "    # 验证集的预测结果存储器，后保存至本地文件\n",
    "    prediction_train = pd.Series()\n",
    "    \n",
    "    # Part 3.交叉验证\n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    for train_part_index, eval_index in kf.split(train[features], train[label]):\n",
    "        # 训练数据封装\n",
    "        train_part = lgb.Dataset(train[features].loc[train_part_index],\n",
    "                                 train[label].loc[train_part_index])\n",
    "        # 测试数据封装\n",
    "        eval = lgb.Dataset(train[features].loc[eval_index],\n",
    "                           train[label].loc[eval_index])\n",
    "        # 依据验证集训练模型\n",
    "        bst = lgb.train(params, train_part, num_boost_round=NBR,\n",
    "                        valid_sets=[train_part, eval],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        early_stopping_rounds=ESR, verbose_eval=VBE)\n",
    "        # 测试集预测结果并纳入prediction_test容器\n",
    "        prediction_test += bst.predict(test[features])\n",
    "        # 验证集预测结果并纳入prediction_train容器\n",
    "        prediction_train = prediction_train.append(pd.Series(bst.predict(train[features].loc[eval_index]),\n",
    "                                                             index=eval_index))\n",
    "        # 验证集预测结果\n",
    "        eval_pre = bst.predict(train[features].loc[eval_index])\n",
    "        # 计算验证集上得分\n",
    "        score = np.sqrt(mean_squared_error(train[label].loc[eval_index].values, eval_pre))\n",
    "        # 纳入cv_score容器\n",
    "        cv_score.append(score)\n",
    "        \n",
    "    # Part 4.打印/输出结果\n",
    "    # 打印验证集得分与平均得分\n",
    "    print(cv_score, sum(cv_score) / 5)\n",
    "    # 将验证集上预测结果写入本地文件\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv(\"preprocess/train_lightgbm.csv\", index=False)\n",
    "    # 将测试集上预测结果写入本地文件\n",
    "    pd.Series(prediction_test / 5).to_csv(\"preprocess/test_lightgbm.csv\", index=False)\n",
    "    # 测试集平均得分作为模型最终预测结果\n",
    "    test['target'] = prediction_test / 5\n",
    "    # 将测试集预测结果写成竞赛要求格式并保存至本地\n",
    "    test[['card_id', 'target']].to_csv(\"result/submission_lightgbm.csv\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3fad7d3-0153-47c0-90ae-9d2eb1de06a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_wrapper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.676517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227016\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1626\n",
      "[LightGBM] [Info] Start training from score -0.390986\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.43695\tvalid's rmse: 3.70629\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttrain's rmse: 3.39251\tvalid's rmse: 3.70281\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.595659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227122\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1629\n",
      "[LightGBM] [Info] Start training from score -0.396781\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.45546\tvalid's rmse: 3.67176\n",
      "[100]\ttrain's rmse: 3.33017\tvalid's rmse: 3.67221\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttrain's rmse: 3.37387\tvalid's rmse: 3.66794\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.572918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227089\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1631\n",
      "[LightGBM] [Info] Start training from score -0.390348\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.43208\tvalid's rmse: 3.72216\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttrain's rmse: 3.38524\tvalid's rmse: 3.71798\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.694756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1624\n",
      "[LightGBM] [Info] Start training from score -0.391392\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.42022\tvalid's rmse: 3.7901\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttrain's rmse: 3.39133\tvalid's rmse: 3.78884\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.567025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227023\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1625\n",
      "[LightGBM] [Info] Start training from score -0.398675\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.46321\tvalid's rmse: 3.60039\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttrain's rmse: 3.43002\tvalid's rmse: 3.59887\n",
      "done\n",
      "{'bagging_fraction': 0.7253952770621912, 'bagging_freq': 5, 'feature_fraction': 0.6972128940985931, 'learning_rate': 0.43437628238508774, 'min_child_samples': 6, 'num_leaves': 60, 'reg_alpha': 0, 'reg_lambda': 1.6139256132729207, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931 \n",
      "[LightGBM] [Info] Start training from score -0.390344 \n",
      "  0%|          | 0/30 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.557619162794617, 'bagging_freq': 6, 'feature_fraction': 0.768520768296847, 'learning_rate': 0.4484899481964635, 'min_child_samples': 1, 'num_leaves': 250, 'reg_alpha': 1, 'reg_lambda': 1.9478998979854978, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                          \n",
      "[LightGBM] [Info] Start training from score -0.390344                          \n",
      "{'bagging_fraction': 0.6089577218903197, 'bagging_freq': 8, 'feature_fraction': 0.9078041789694723, 'learning_rate': 0.4000654698261548, 'min_child_samples': 26, 'num_leaves': 60, 'reg_alpha': 4, 'reg_lambda': 9.739071431781486, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                             \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                          \n",
      "[LightGBM] [Info] Start training from score -0.390344                          \n",
      "{'bagging_fraction': 0.5823692068559665, 'bagging_freq': 1, 'feature_fraction': 0.9863236467851518, 'learning_rate': 0.44826974213381765, 'min_child_samples': 6, 'num_leaves': 190, 'reg_alpha': 8, 'reg_lambda': 6.424961074528348, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.598225211619325, 'bagging_freq': 4, 'feature_fraction': 0.5548282810909009, 'learning_rate': 0.33699901703548696, 'min_child_samples': 6, 'num_leaves': 100, 'reg_alpha': 5, 'reg_lambda': 8.56187185369514, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9653168636499914, 'bagging_freq': 2, 'feature_fraction': 0.7958338878675355, 'learning_rate': 0.49191469387124415, 'min_child_samples': 6, 'num_leaves': 120, 'reg_alpha': 0, 'reg_lambda': 6.281210819853246, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9746881685291604, 'bagging_freq': 5, 'feature_fraction': 0.6646803214513162, 'learning_rate': 0.07529481190470996, 'min_child_samples': 1, 'num_leaves': 270, 'reg_alpha': 8, 'reg_lambda': 5.37208795616958, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9594369823462314, 'bagging_freq': 1, 'feature_fraction': 0.5205458529613629, 'learning_rate': 0.10394361538901523, 'min_child_samples': 11, 'num_leaves': 180, 'reg_alpha': 9, 'reg_lambda': 8.54732560156507, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.184174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.5239402528699113, 'bagging_freq': 4, 'feature_fraction': 0.7242087970134551, 'learning_rate': 0.1388688694778799, 'min_child_samples': 16, 'num_leaves': 120, 'reg_alpha': 0, 'reg_lambda': 7.4552808665141175, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.7002922718759523, 'bagging_freq': 1, 'feature_fraction': 0.6995945996396362, 'learning_rate': 0.13683006962337202, 'min_child_samples': 1, 'num_leaves': 170, 'reg_alpha': 8, 'reg_lambda': 9.573241379549104, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.9740731891987577, 'bagging_freq': 9, 'feature_fraction': 0.8294212073704622, 'learning_rate': 0.4788786165054211, 'min_child_samples': 21, 'num_leaves': 180, 'reg_alpha': 3, 'reg_lambda': 9.025378633668943, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.6595660453511591, 'bagging_freq': 3, 'feature_fraction': 0.7067334738059636, 'learning_rate': 0.03476014344160344, 'min_child_samples': 6, 'num_leaves': 280, 'reg_alpha': 7, 'reg_lambda': 1.5530335205049572, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.6633836872563099, 'bagging_freq': 6, 'feature_fraction': 0.5393971364268482, 'learning_rate': 0.4475746464086467, 'min_child_samples': 21, 'num_leaves': 240, 'reg_alpha': 5, 'reg_lambda': 9.96781356536865, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.8489543397224686, 'bagging_freq': 7, 'feature_fraction': 0.7582778265282211, 'learning_rate': 0.2222331623940236, 'min_child_samples': 21, 'num_leaves': 120, 'reg_alpha': 7, 'reg_lambda': 9.191685626283043, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.8489434703946281, 'bagging_freq': 5, 'feature_fraction': 0.8206802208124425, 'learning_rate': 0.04617153690285374, 'min_child_samples': 26, 'num_leaves': 270, 'reg_alpha': 0, 'reg_lambda': 6.1154939604145255, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                           \n",
      "[LightGBM] [Info] Start training from score -0.390344                           \n",
      "{'bagging_fraction': 0.5722064005547208, 'bagging_freq': 9, 'feature_fraction': 0.6351076955262891, 'learning_rate': 0.24123365491719742, 'min_child_samples': 16, 'num_leaves': 220, 'reg_alpha': 4, 'reg_lambda': 5.435241604857383, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.876943709541165, 'bagging_freq': 1, 'feature_fraction': 0.7520250111432751, 'learning_rate': 0.27978139134976193, 'min_child_samples': 16, 'num_leaves': 250, 'reg_alpha': 0, 'reg_lambda': 9.889444738399005, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7292457974834843, 'bagging_freq': 1, 'feature_fraction': 0.5605178583746184, 'learning_rate': 0.0750382696349759, 'min_child_samples': 26, 'num_leaves': 30, 'reg_alpha': 3, 'reg_lambda': 8.434389500726724, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.212526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7623620409611478, 'bagging_freq': 5, 'feature_fraction': 0.9037817698710914, 'learning_rate': 0.11935511419050072, 'min_child_samples': 21, 'num_leaves': 50, 'reg_alpha': 6, 'reg_lambda': 9.525599018301525, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.6959365208552413, 'bagging_freq': 4, 'feature_fraction': 0.8682613864600894, 'learning_rate': 0.3540190069136353, 'min_child_samples': 11, 'num_leaves': 70, 'reg_alpha': 8, 'reg_lambda': 1.8364446123307276, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7790707500769768, 'bagging_freq': 5, 'feature_fraction': 0.9823224422761904, 'learning_rate': 0.18097980740543457, 'min_child_samples': 26, 'num_leaves': 50, 'reg_alpha': 6, 'reg_lambda': 3.70583513118315, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7657229397838268, 'bagging_freq': 3, 'feature_fraction': 0.6048086694416244, 'learning_rate': 0.18083227043013056, 'min_child_samples': 21, 'num_leaves': 30, 'reg_alpha': 3, 'reg_lambda': 7.765420130465819, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.7941491322120129, 'bagging_freq': 2, 'feature_fraction': 0.9314060907023993, 'learning_rate': 0.02215568922918173, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 3.921799580171095, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.8156411479061829, 'bagging_freq': 2, 'feature_fraction': 0.9453575093796732, 'learning_rate': 0.015016007831064087, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 3.6758012630853103, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9022336069269954, 'bagging_freq': 2, 'feature_fraction': 0.9373662317255621, 'learning_rate': 0.014947332175194025, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 3.5907566887206896, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9092910898548142, 'bagging_freq': 2, 'feature_fraction': 0.9587253380203777, 'learning_rate': 0.01594569445481636, 'min_child_samples': 26, 'num_leaves': 80, 'reg_alpha': 2, 'reg_lambda': 0.5437059106621431, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9243731638563496, 'bagging_freq': 2, 'feature_fraction': 0.8579304338996762, 'learning_rate': 0.07045436429758375, 'min_child_samples': 26, 'num_leaves': 10, 'reg_alpha': 2, 'reg_lambda': 3.6181498300907533, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.8208518394986082, 'bagging_freq': 2, 'feature_fraction': 0.9942064788262652, 'learning_rate': 0.17680977265314285, 'min_child_samples': 26, 'num_leaves': 230, 'reg_alpha': 2, 'reg_lambda': 0.014934884031477136, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.9087334379512036, 'bagging_freq': 8, 'feature_fraction': 0.9435725455149249, 'learning_rate': 0.28640982898261946, 'min_child_samples': 26, 'num_leaves': 130, 'reg_alpha': 2, 'reg_lambda': 2.818017545083271, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.188394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "{'bagging_fraction': 0.8733261239697325, 'bagging_freq': 2, 'feature_fraction': 0.8775960565074609, 'learning_rate': 0.011582875040907454, 'min_child_samples': 11, 'num_leaves': 210, 'reg_alpha': 9, 'reg_lambda': 4.553491961304738, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 2020}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.183489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65975                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396931                            \n",
      "[LightGBM] [Info] Start training from score -0.390344                            \n",
      "100%|██████████| 30/30 [02:54<00:00,  5.83s/trial, best loss: 3.6844192003528775]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-3f2f3376e96b>:27: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  prediction_train = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65666\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.390986\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.75892\tvalid's rmse: 3.77103\n",
      "[100]\ttrain's rmse: 3.71868\tvalid's rmse: 3.73851\n",
      "[150]\ttrain's rmse: 3.69462\tvalid's rmse: 3.721\n",
      "[200]\ttrain's rmse: 3.67853\tvalid's rmse: 3.71087\n",
      "[250]\ttrain's rmse: 3.66669\tvalid's rmse: 3.70432\n",
      "[300]\ttrain's rmse: 3.65751\tvalid's rmse: 3.69995\n",
      "[350]\ttrain's rmse: 3.65049\tvalid's rmse: 3.69762\n",
      "[400]\ttrain's rmse: 3.64309\tvalid's rmse: 3.69551\n",
      "[450]\ttrain's rmse: 3.63597\tvalid's rmse: 3.69377\n",
      "[500]\ttrain's rmse: 3.63008\tvalid's rmse: 3.6925\n",
      "[550]\ttrain's rmse: 3.62462\tvalid's rmse: 3.69105\n",
      "[600]\ttrain's rmse: 3.6198\tvalid's rmse: 3.69013\n",
      "[650]\ttrain's rmse: 3.61443\tvalid's rmse: 3.68931\n",
      "[700]\ttrain's rmse: 3.61005\tvalid's rmse: 3.68884\n",
      "[750]\ttrain's rmse: 3.60491\tvalid's rmse: 3.68812\n",
      "[800]\ttrain's rmse: 3.59974\tvalid's rmse: 3.68759\n",
      "[850]\ttrain's rmse: 3.59474\tvalid's rmse: 3.68714\n",
      "Early stopping, best iteration is:\n",
      "[831]\ttrain's rmse: 3.5965\tvalid's rmse: 3.68697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.349296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65677\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.396781\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.76719\tvalid's rmse: 3.73854\n",
      "[100]\ttrain's rmse: 3.72832\tvalid's rmse: 3.70102\n",
      "[150]\ttrain's rmse: 3.70615\tvalid's rmse: 3.68157\n",
      "[200]\ttrain's rmse: 3.68981\tvalid's rmse: 3.6711\n",
      "[250]\ttrain's rmse: 3.67731\tvalid's rmse: 3.6642\n",
      "[300]\ttrain's rmse: 3.6682\tvalid's rmse: 3.66021\n",
      "[350]\ttrain's rmse: 3.66021\tvalid's rmse: 3.65732\n",
      "[400]\ttrain's rmse: 3.653\tvalid's rmse: 3.65522\n",
      "[450]\ttrain's rmse: 3.6464\tvalid's rmse: 3.65337\n",
      "[500]\ttrain's rmse: 3.63997\tvalid's rmse: 3.65184\n",
      "[550]\ttrain's rmse: 3.63353\tvalid's rmse: 3.6508\n",
      "[600]\ttrain's rmse: 3.62768\tvalid's rmse: 3.64985\n",
      "[650]\ttrain's rmse: 3.62235\tvalid's rmse: 3.64887\n",
      "[700]\ttrain's rmse: 3.61719\tvalid's rmse: 3.64818\n",
      "[750]\ttrain's rmse: 3.61244\tvalid's rmse: 3.64785\n",
      "[800]\ttrain's rmse: 3.60741\tvalid's rmse: 3.6471\n",
      "[850]\ttrain's rmse: 3.60239\tvalid's rmse: 3.64632\n",
      "[900]\ttrain's rmse: 3.59807\tvalid's rmse: 3.64592\n",
      "[950]\ttrain's rmse: 3.59319\tvalid's rmse: 3.64498\n",
      "[1000]\ttrain's rmse: 3.58882\tvalid's rmse: 3.64452\n",
      "Early stopping, best iteration is:\n",
      "[998]\ttrain's rmse: 3.58903\tvalid's rmse: 3.64451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.353090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65684\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.390348\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.75231\tvalid's rmse: 3.78794\n",
      "[100]\ttrain's rmse: 3.71093\tvalid's rmse: 3.75345\n",
      "[150]\ttrain's rmse: 3.68701\tvalid's rmse: 3.73658\n",
      "[200]\ttrain's rmse: 3.67191\tvalid's rmse: 3.72698\n",
      "[250]\ttrain's rmse: 3.66002\tvalid's rmse: 3.72123\n",
      "[300]\ttrain's rmse: 3.65114\tvalid's rmse: 3.71716\n",
      "[350]\ttrain's rmse: 3.64347\tvalid's rmse: 3.71463\n",
      "[400]\ttrain's rmse: 3.63661\tvalid's rmse: 3.71266\n",
      "[450]\ttrain's rmse: 3.63053\tvalid's rmse: 3.71135\n",
      "[500]\ttrain's rmse: 3.62438\tvalid's rmse: 3.71013\n",
      "[550]\ttrain's rmse: 3.61892\tvalid's rmse: 3.70927\n",
      "[600]\ttrain's rmse: 3.61344\tvalid's rmse: 3.70822\n",
      "[650]\ttrain's rmse: 3.60779\tvalid's rmse: 3.70713\n",
      "[700]\ttrain's rmse: 3.60292\tvalid's rmse: 3.70661\n",
      "[750]\ttrain's rmse: 3.59785\tvalid's rmse: 3.70588\n",
      "[800]\ttrain's rmse: 3.59275\tvalid's rmse: 3.70488\n",
      "[850]\ttrain's rmse: 3.588\tvalid's rmse: 3.70413\n",
      "[900]\ttrain's rmse: 3.58365\tvalid's rmse: 3.70404\n",
      "Early stopping, best iteration is:\n",
      "[870]\ttrain's rmse: 3.58625\tvalid's rmse: 3.70395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.305438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65642\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.391392\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.73315\tvalid's rmse: 3.86928\n",
      "[100]\ttrain's rmse: 3.69309\tvalid's rmse: 3.83508\n",
      "[150]\ttrain's rmse: 3.66977\tvalid's rmse: 3.81704\n",
      "[200]\ttrain's rmse: 3.65402\tvalid's rmse: 3.80625\n",
      "[250]\ttrain's rmse: 3.64247\tvalid's rmse: 3.79953\n",
      "[300]\ttrain's rmse: 3.63288\tvalid's rmse: 3.79472\n",
      "[350]\ttrain's rmse: 3.62507\tvalid's rmse: 3.79137\n",
      "[400]\ttrain's rmse: 3.61782\tvalid's rmse: 3.78885\n",
      "[450]\ttrain's rmse: 3.61148\tvalid's rmse: 3.78654\n",
      "[500]\ttrain's rmse: 3.60518\tvalid's rmse: 3.78439\n",
      "[550]\ttrain's rmse: 3.59867\tvalid's rmse: 3.78269\n",
      "[600]\ttrain's rmse: 3.59283\tvalid's rmse: 3.78127\n",
      "[650]\ttrain's rmse: 3.58721\tvalid's rmse: 3.77968\n",
      "[700]\ttrain's rmse: 3.58204\tvalid's rmse: 3.7786\n",
      "[750]\ttrain's rmse: 3.57702\tvalid's rmse: 3.77795\n",
      "[800]\ttrain's rmse: 3.57227\tvalid's rmse: 3.7771\n",
      "[850]\ttrain's rmse: 3.56756\tvalid's rmse: 3.77617\n",
      "[900]\ttrain's rmse: 3.56254\tvalid's rmse: 3.77507\n",
      "[950]\ttrain's rmse: 3.55836\tvalid's rmse: 3.77424\n",
      "[1000]\ttrain's rmse: 3.55367\tvalid's rmse: 3.7737\n",
      "[1050]\ttrain's rmse: 3.54943\tvalid's rmse: 3.77328\n",
      "[1100]\ttrain's rmse: 3.54517\tvalid's rmse: 3.77277\n",
      "[1150]\ttrain's rmse: 3.54089\tvalid's rmse: 3.77242\n",
      "Early stopping, best iteration is:\n",
      "[1144]\ttrain's rmse: 3.54163\tvalid's rmse: 3.77227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\vdmion\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.350972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65695\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.398675\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.78477\tvalid's rmse: 3.65732\n",
      "[100]\ttrain's rmse: 3.74396\tvalid's rmse: 3.62525\n",
      "[150]\ttrain's rmse: 3.72006\tvalid's rmse: 3.6094\n",
      "[200]\ttrain's rmse: 3.7039\tvalid's rmse: 3.59961\n",
      "[250]\ttrain's rmse: 3.69286\tvalid's rmse: 3.59368\n",
      "[300]\ttrain's rmse: 3.68357\tvalid's rmse: 3.59002\n",
      "[350]\ttrain's rmse: 3.67565\tvalid's rmse: 3.58705\n",
      "[400]\ttrain's rmse: 3.66878\tvalid's rmse: 3.58453\n",
      "[450]\ttrain's rmse: 3.66276\tvalid's rmse: 3.5828\n",
      "[500]\ttrain's rmse: 3.65653\tvalid's rmse: 3.58089\n",
      "[550]\ttrain's rmse: 3.65107\tvalid's rmse: 3.57947\n",
      "[600]\ttrain's rmse: 3.64527\tvalid's rmse: 3.57869\n",
      "[650]\ttrain's rmse: 3.64029\tvalid's rmse: 3.57741\n",
      "[700]\ttrain's rmse: 3.63434\tvalid's rmse: 3.57659\n",
      "[750]\ttrain's rmse: 3.62887\tvalid's rmse: 3.57541\n",
      "[800]\ttrain's rmse: 3.62374\tvalid's rmse: 3.57487\n",
      "[850]\ttrain's rmse: 3.61877\tvalid's rmse: 3.57409\n",
      "[900]\ttrain's rmse: 3.61421\tvalid's rmse: 3.57325\n",
      "[950]\ttrain's rmse: 3.60936\tvalid's rmse: 3.57294\n",
      "[1000]\ttrain's rmse: 3.60497\tvalid's rmse: 3.57253\n",
      "Early stopping, best iteration is:\n",
      "[1000]\ttrain's rmse: 3.60497\tvalid's rmse: 3.57253\n",
      "[3.6869706135632367, 3.6445135024361908, 3.7039487803864932, 3.772271999086466, 3.5725331932165627] 3.6760476177377894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-3f2f3376e96b>:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['target'] = prediction_test / 5\n"
     ]
    }
   ],
   "source": [
    "train_LGBM, test_LGBM = feature_select_wrapper(train, test)\n",
    "best_clf = param_hyperopt(train_LGBM)\n",
    "train_predict(train_LGBM, test_LGBM, best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b855e1f-e0a8-4d0a-bbee-1eed6a798443",
   "metadata": {},
   "source": [
    "接下来即可在竞赛主页提交预测结果。最终公榜私榜评分如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e413b62-3fb2-4737-a7cc-4d73a0d476d9",
   "metadata": {},
   "source": [
    "<center><img src=\"https://s2.loli.net/2021/12/09/EnekwUaMIVKQfDt.png\" alt=\"image-20211209173249232\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccb3dc-ae3d-409b-893f-77b18919281c",
   "metadata": {},
   "source": [
    "对比此前结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17ad27-432b-4e25-aa8e-a23150bfbe4d",
   "metadata": {},
   "source": [
    "| 模型 | Private Score | Public Score |\n",
    "| ------ | ------ | ------ |\n",
    "| randomforest | 3.65455 | 3.74969 |\n",
    "| randomforest+validation | 3.65173 | 3.74954 |\n",
    "| LightGBM | 3.69723 | 3.80436 |\n",
    "| LightGBM+validation | 3.64403 | 3.73875 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae8118-f11c-477b-bfd7-3890006a86f8",
   "metadata": {},
   "source": [
    "能够看出，经过交叉验证后输出的平均值结果，较此前的预测评分，有较大提升，这也是目前我们跑出的最好成绩。同时，交叉验证的作用已得到充分征明，后续在进行其他模型训练时仅考虑模型+交叉验证的输出结果，不再进行单模型结果输出。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
